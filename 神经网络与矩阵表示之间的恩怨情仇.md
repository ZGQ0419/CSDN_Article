@[TOC](目录)

# 写在前面
&emsp;&emsp;最近准备使用深度神经网络来训练棋类模型，所以准备好好学习一下神经网络各种参数结构；重在使用，所以不会按照顺序详细讲解神经网络过程，本篇博客属于小白个人总结，大佬请直接忽视。

# 神经网络结构
&emsp;&emsp;DNN主要由很多层的神经网络，每一层中有很多个神经元组成；<font color=#ff00 size=3 face="宋体">**每个神经元**</font> 是神经网络最小组成单位，<font color=#ff00 size=3 face="宋体">**每个神经元**</font>由权重 **`W`**  和偏置 **`b`** 组成，`W`为 [n, 1] 的向量，*b*为常数；每个神经元可以独自完成对输入数据 *`X`* 进行 *`XW+b`* 运算。如图是一层网络中一个神经元的结构：
![单个神经元结构](https://img-blog.csdnimg.cn/20191025205820941.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0d1b1FpWmhhbmc=,size_16,color_FFFFFF,t_70)

# 矩阵表达
&emsp;&emsp;在每层神经网络中矩阵的表达方式为：**Z = XW+b**

|参数|矩阵形状|矩阵向量注释|备注|
|-|:-|:-|:-|
| **X** | [n_batch, n_inputs] | **n_batch**：表示每次输入数据的条数；**n_inputs**：表示每条数据包含的特征数（Xi 的个数）|**X**数据每一行是一条数据，每一列是数据的一个属性|
| **W** | [n_inputs，n_neurons]|**n_inputs**：同上 ；**n_neurons**：表示该层网络的神经元数量|**W**的每一列是每个神经元对应的w向量，每一行应该没有意义|
|**b**|[1,n_neurons]|**n_neurons**：同上|该层神经网络的每个神经元有一个偏置b|
|**Z**|[n_batch,n_neurons]|均同上|这里的Z为每一层神经网络的输出，每行为一条数据的n_neurons个神经元的不同输出，每一列为每个神经元对不同数据的计算输出 |


# 总结
&emsp;&emsp;每层神经网络中每个神经元都是对每条输入数据在不同属性上（Xi）采取不同的权重计算得到的结果。
